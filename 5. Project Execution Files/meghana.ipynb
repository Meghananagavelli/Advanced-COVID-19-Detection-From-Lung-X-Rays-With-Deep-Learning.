{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azeLkx2LTllu",
        "outputId": "0621182e-0482-4bd7-eb95-6a531e11c9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/covid19-radiography-database\n",
            "Path to dataset files: /kaggle/input/covid19-radiography-database\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m124.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m123.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hFound 33866 images belonging to 4 classes.\n",
            "Found 8464 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "dataset_path = kagglehub.dataset_download(\"tawsifurrahman/covid19-radiography-database\")\n",
        "\n",
        "# Step 2: Point to the folder that contains class subfolders (COVID, Normal, etc.)\n",
        "data_path = os.path.join(dataset_path, \"COVID-19_Radiography_Dataset\")\n",
        "print(\"Path to dataset files:\",dataset_path)\n",
        "train_data_path = os.path.join(dataset_path, 'train')\n",
        "test_data_path = os.path.join(dataset_path, 'test') # Path to the test data\n",
        "print(\"Path to dataset files:\", dataset_path)\n",
        "\n",
        "!pip install -q tensorflow\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Configure ImageDataGenerator\n",
        "# You might want a separate ImageDataGenerator for test data without augmentations\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) # Only rescaling for test data\n",
        "\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (299, 299))  # resize\n",
        "    if image.shape[-1] == 1:\n",
        "        image = tf.image.grayscale_to_rgb(image)  # (299, 299, 1) → (299, 299, 3)\n",
        "    image = image / 255.0  # normalize\n",
        "    return image, label\n",
        "\n",
        "# Step 3: Define ImageDataGenerators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # 20% for validation\n",
        ")\n",
        "\n",
        "# Step 4: Training data\n",
        "train_data = datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Step 5: Validation data\n",
        "val_data = datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3ISoKRyLYqL",
        "outputId": "3c216d50-0187-4930-f92d-3d674719e655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading dataset...\n",
            "Found 33866 images belonging to 4 classes.\n",
            "Found 8464 images belonging to 4 classes.\n",
            "\n",
            "Loading MobileNetV2 base model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-42f7cfc6f6fc>:46: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Training model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.2585 - loss: 1.7761 - val_accuracy: 0.4469 - val_loss: 1.2253\n",
            "Epoch 2/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.3599 - loss: 1.4887 - val_accuracy: 0.5094 - val_loss: 1.1202\n",
            "Epoch 3/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.4187 - loss: 1.3223 - val_accuracy: 0.5344 - val_loss: 1.0743\n",
            "Epoch 4/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.4386 - loss: 1.3563 - val_accuracy: 0.5906 - val_loss: 1.0225\n",
            "Epoch 5/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.4564 - loss: 1.2820 - val_accuracy: 0.5906 - val_loss: 1.0013\n",
            "Epoch 6/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.4500 - loss: 1.3313 - val_accuracy: 0.6438 - val_loss: 0.9167\n",
            "Epoch 7/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.4925 - loss: 1.1987 - val_accuracy: 0.6750 - val_loss: 0.8906\n",
            "Epoch 8/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.4873 - loss: 1.1751 - val_accuracy: 0.6469 - val_loss: 0.8989\n",
            "Epoch 9/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 2s/step - accuracy: 0.4851 - loss: 1.1979 - val_accuracy: 0.6406 - val_loss: 0.9124\n",
            "Epoch 10/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - accuracy: 0.4810 - loss: 1.1928 - val_accuracy: 0.6687 - val_loss: 0.8937\n",
            "Epoch 11/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.5158 - loss: 1.1766 - val_accuracy: 0.6750 - val_loss: 0.9059\n",
            "Epoch 12/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.5361 - loss: 1.1283 - val_accuracy: 0.6750 - val_loss: 0.8560\n",
            "Epoch 13/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5019 - loss: 1.1660 - val_accuracy: 0.6781 - val_loss: 0.8491\n",
            "Epoch 14/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.5532 - loss: 1.0691 - val_accuracy: 0.6875 - val_loss: 0.7938\n",
            "Epoch 15/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 3s/step - accuracy: 0.5407 - loss: 1.0854 - val_accuracy: 0.6781 - val_loss: 0.8183\n",
            "Epoch 16/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.5447 - loss: 1.0753 - val_accuracy: 0.7063 - val_loss: 0.7952\n",
            "Epoch 17/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.5287 - loss: 1.1171 - val_accuracy: 0.6844 - val_loss: 0.7977\n",
            "Epoch 18/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 3s/step - accuracy: 0.5813 - loss: 1.0356 - val_accuracy: 0.7500 - val_loss: 0.6925\n",
            "Epoch 19/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 2s/step - accuracy: 0.5468 - loss: 1.1296 - val_accuracy: 0.7250 - val_loss: 0.7273\n",
            "Epoch 20/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5667 - loss: 1.0558 - val_accuracy: 0.7188 - val_loss: 0.7602\n",
            "Epoch 21/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5789 - loss: 1.0154 - val_accuracy: 0.6844 - val_loss: 0.7902\n",
            "Epoch 22/25\n",
            "\u001b[1m 9/50\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:05\u001b[0m 2s/step - accuracy: 0.6189 - loss: 0.9243"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 621ms/step - accuracy: 0.5983 - loss: 0.9786 - val_accuracy: 0.6844 - val_loss: 0.8136\n",
            "Epoch 23/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.5593 - loss: 1.0644 - val_accuracy: 0.6844 - val_loss: 0.7806\n",
            "Epoch 24/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 2s/step - accuracy: 0.5851 - loss: 1.0197 - val_accuracy: 0.7000 - val_loss: 0.7671\n",
            "Epoch 25/25\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 2s/step - accuracy: 0.6038 - loss: 0.9868 - val_accuracy: 0.7406 - val_loss: 0.7563\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Download dataset\n",
        "print(\"\\nDownloading dataset...\")\n",
        "dataset_path = kagglehub.dataset_download(\"tawsifurrahman/covid19-radiography-database\")\n",
        "data_path = os.path.join(dataset_path, \"COVID-19_Radiography_Dataset\")\n",
        "\n",
        "# Step 2: Data generators with preprocessing\n",
        "img_size = (299, 299)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = train_datagen.flow_from_directory(\n",
        "    data_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Step 3: Load MobileNetV2 base model\n",
        "print(\"\\nLoading MobileNetV2 base model...\")\n",
        "base_model = MobileNetV2(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(4, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Step 4: Compile\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train\n",
        "print(\"\\nTraining model...\")\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=25,\n",
        "    steps_per_epoch=50,\n",
        "    validation_steps=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6exkSJGKPtss"
      },
      "outputs": [],
      "source": [
        "# Optional: Image preprocessing for deployment\n",
        "\n",
        "def preprocess_input_image(img_path):\n",
        "    img = load_img(img_path, target_size=img_size)\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = tf.image.grayscale_to_rgb(img_array) if img_array.shape[-1] == 1 else img_array\n",
        "    img_array = img_array / 255.0\n",
        "    return np.expand_dims(img_array, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPgHidYmQQaF",
        "outputId": "83287100-9e26-4c41-ec61-1c282bffdf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"covid_classification_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GFS4Zvk-QSRH",
        "outputId": "2d98bd56-0c99-4a4a-933b-bdaa7393fadb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ca108e4f-3cf3-4a65-bfe9-17238cda9045\", \"covid_classification_model.h5\", 9631488)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"covid_classification_model.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}